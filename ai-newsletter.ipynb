{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://newsletter.theaiedge.io/p/deep-dive-how-to-automate-writing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the top news\n",
    "\n",
    "# The NewsAPI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NewsAPIException",
     "evalue": "{'status': 'error', 'code': 'apiKeyMissing', 'message': 'Your API key is missing. Append this to the URL with the apiKey param, or use the x-api-key HTTP header.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# TODO Error when creating an account\u001b[39;00m\n\u001b[1;32m      7\u001b[0m newsapi \u001b[39m=\u001b[39m NewsApiClient(api_key\u001b[39m=\u001b[39mNEWS_API_JSON_API_KEY)\n\u001b[0;32m----> 9\u001b[0m everything \u001b[39m=\u001b[39m newsapi\u001b[39m.\u001b[39;49mget_everything(\n\u001b[1;32m     10\u001b[0m     q\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39martifical intelligence\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     from_param\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m2023-06-19\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     sort_by\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrelevancy\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     language\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m everything[\u001b[39m\"\u001b[39m\u001b[39marticles\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/ai-newsletter/.venv/lib/python3.9/site-packages/newsapi/newsapi_client.py:334\u001b[0m, in \u001b[0;36mNewsApiClient.get_everything\u001b[0;34m(self, q, qintitle, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m# Check Status of Request\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m requests\u001b[39m.\u001b[39mcodes\u001b[39m.\u001b[39mok:\n\u001b[0;32m--> 334\u001b[0m     \u001b[39mraise\u001b[39;00m NewsAPIException(r\u001b[39m.\u001b[39mjson())\n\u001b[1;32m    336\u001b[0m \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'apiKeyMissing', 'message': 'Your API key is missing. Append this to the URL with the apiKey param, or use the x-api-key HTTP header.'}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "NEWS_API_JSON_API_KEY = os.environ.get(\"NEWS_API_JSON_API_KEY\")\n",
    "\n",
    "# TODO Error when creating an account\n",
    "newsapi = NewsApiClient(api_key=NEWS_API_JSON_API_KEY)\n",
    "\n",
    "everything = newsapi.get_everything(\n",
    "    q=\"artifical intelligence\",\n",
    "    from_param=\"2023-06-19\",\n",
    "    sort_by=\"relevancy\",\n",
    "    language=\"en\",\n",
    ")\n",
    "\n",
    "everything[\"articles\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Amazon plans to invest another $15 billion in India by 2030\\nThis week in AI: Big tech bets billions on machine learning tools\\nHow one software engineer is turning Silicon Valley Bank's collapse story into a musical\\nDeal Dive: Caraway shows what else digital health can do\\nHacker responsible for 2020 Twitter breach sentenced to prison\\nWhat happens if regulators nix the $20B Adobe-Figma deal?\\nOceanGate fires a whistleblower, hackers threaten to leak Reddit data, and Marvel embraces AI art\\nWhy smart AI regulation is vital for innovation and U.S. leadership\\nTechCrunch+ roundup: AI + travel, fusion investor survey, why you'll never get funding\\nKeeping tabs on dry powder and university spinouts\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temporary workaround\n",
    "# load fake_news data from a json file fake_news.json\n",
    "import json\n",
    "\n",
    "fake_news = json.load(open(\"fake_news.json\"))\n",
    "\n",
    "everything = fake_news\n",
    "\n",
    "title_list = \"\\n\".join([\n",
    "    article[\"title\"] for article in everything[\"articles\"]\n",
    "])\n",
    "\n",
    "title_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the top news\n",
    "\n",
    "Use GPT to identify the most 3 most interesting articles to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "top_news_tempalte = \"\"\"\n",
    "extract from the following list the 10 most important news about machine learning. Return the answer as a python list. \n",
    "\n",
    "For example: [\"text 1\", \"text 2\", \"text 3\"]\n",
    "\n",
    "{list}\n",
    "\"\"\"\n",
    "\n",
    "TOP_NEWS_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"list\"],\n",
    "    template=top_news_tempalte,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=TOP_NEWS_PROMPT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This week in AI: Big tech bets billions on machine learning tools\", \"Hacker responsible for 2020 Twitter breach sentenced to prison\", \"Why smart AI regulation is vital for innovation and U.S. leadership\", \"TechCrunch+ roundup: AI + travel, fusion investor survey, why you'll never get funding\", \"Keeping tabs on dry powder and university spinouts\", \"Amazon plans to invest another $15 billion in India by 2030\", \"What happens if regulators nix the $20B Adobe-Figma deal?\", \"OceanGate fires a whistleblower, hackers threaten to leak Reddit data, and Marvel embraces AI art\", \"Deal Dive: Caraway shows what else digital health can do\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This week in AI: Big tech bets billions on machine learning tools',\n",
       " 'Hacker responsible for 2020 Twitter breach sentenced to prison',\n",
       " 'Why smart AI regulation is vital for innovation and U.S. leadership',\n",
       " \"TechCrunch+ roundup: AI + travel, fusion investor survey, why you'll never get funding\",\n",
       " 'Keeping tabs on dry powder and university spinouts',\n",
       " 'Amazon plans to invest another $15 billion in India by 2030',\n",
       " 'What happens if regulators nix the $20B Adobe-Figma deal?',\n",
       " 'OceanGate fires a whistleblower, hackers threaten to leak Reddit data, and Marvel embraces AI art',\n",
       " 'Deal Dive: Caraway shows what else digital health can do']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# We send the prompt to the LLM\n",
    "top_str = chain.run(title_list)\n",
    "print(top_str)\n",
    "\n",
    "# And we convert the result as a python list\n",
    "top_list = ast.literal_eval(top_str)\n",
    "top_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Amazon plans to invest another $15 billion in India by 2030',\n",
       "  'url': 'https://techcrunch.com/2023/06/23/amazon-investment-india-jassy-modi/'},\n",
       " {'title': 'This week in AI: Big tech bets billions on machine learning tools',\n",
       "  'url': 'https://techcrunch.com/2023/06/24/this-week-in-ai-big-tech-bets-billions-on-machine-learning-tools/'},\n",
       " {'title': 'Deal Dive: Caraway shows what else digital health can do',\n",
       "  'url': 'https://techcrunch.com/2023/06/24/caraway-digital-health-fundraising/'},\n",
       " {'title': 'Hacker responsible for 2020 Twitter breach sentenced to prison',\n",
       "  'url': 'https://techcrunch.com/2023/06/23/twitter-hacker-sentenced-prison/'},\n",
       " {'title': 'What happens if regulators nix the $20B Adobe-Figma deal?',\n",
       "  'url': 'https://techcrunch.com/2023/06/23/adobe-figma-deal-regulators/'},\n",
       " {'title': 'OceanGate fires a whistleblower, hackers threaten to leak Reddit data, and Marvel embraces AI art',\n",
       "  'url': 'https://techcrunch.com/2023/06/24/oceangate-fires-a-whistleblower-hackers-threaten-to-leak-reddit-data-and-marvel-embraces-ai-art/'},\n",
       " {'title': 'Why smart AI regulation is vital for innovation and U.S. leadership',\n",
       "  'url': 'https://techcrunch.com/2023/06/23/why-smart-ai-regulation-is-vital-for-innovation-and-u-s-leadership/'},\n",
       " {'title': \"TechCrunch+ roundup: AI + travel, fusion investor survey, why you'll never get funding\",\n",
       "  'url': 'https://techcrunch.com/2023/06/23/techcrunch-roundup-ai-travel-products-fusion-investor-survey-why-youll-never-get-funding/'},\n",
       " {'title': 'Keeping tabs on dry powder and university spinouts',\n",
       "  'url': 'https://techcrunch.com/2023/06/24/venture-capital-university-spinouts/'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match titles with the related URLs\n",
    "top_news = [\n",
    "    {\n",
    "        \"title\": article[\"title\"],\n",
    "        \"url\": article[\"url\"],\n",
    "    }\n",
    "    for article in everything[\"articles\"]\n",
    "    if article[\"title\"] in top_list\n",
    "]\n",
    "\n",
    "top_news"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing the news\n",
    "\n",
    "## Extracting the news text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def get_text_from_articles(url):\n",
    "    page = urlopen(url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    return soup.get_text()\n",
    "\n",
    "for news_dict in top_news:\n",
    "    try:\n",
    "        article_content = get_text_from_articles(news_dict[\"url\"])\n",
    "        news_dict[\"content\"] = article_content\n",
    "    except:\n",
    "        news_dict[\"content\"] = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the content\n",
    "\n",
    "Stuff strategy\n",
    "Combine strategy\n",
    "Refine strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2868, which is longer than the specified 1000\n",
      "Created a chunk of size 2609, which is longer than the specified 1000\n",
      "Created a chunk of size 3233, which is longer than the specified 1000\n",
      "Created a chunk of size 1873, which is longer than the specified 1000\n",
      "Created a chunk of size 2280, which is longer than the specified 1000\n",
      "Created a chunk of size 3814, which is longer than the specified 1000\n",
      "Created a chunk of size 2757, which is longer than the specified 1000\n",
      "Created a chunk of size 5546, which is longer than the specified 1000\n",
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1297, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon CEO Andy Jassy plans to invest an additional $15bn in India by 2030, with most of the funds earmarked for expanding Amazon Web Services. This doubles the company's investment in the country, and follows a meeting with Indian Prime Minister Narendra Modi. Amazon and other major tech companies such as Walmart and Google are making significant investments in India, which could boost the country's tech industry and create jobs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "def get_summary(text):\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "    combine_template = \"\"\"\n",
    "    Your job is to produce a concise summary of news article\n",
    "    Provide the important points and explain why they matter\n",
    "    The summary is for a blog so it has to be exciting to read\n",
    "\n",
    "    Write a concise summary of the following:\n",
    "\n",
    "    {text}\n",
    "\n",
    "    CONCISE SUMMARY:\n",
    "    \"\"\"\n",
    "\n",
    "    combine_prompt = PromptTemplate(\n",
    "        template=combine_template,\n",
    "        input_variables=[\"text\"],\n",
    "    )\n",
    "\n",
    "    chart_text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0,\n",
    "    )\n",
    "    \n",
    "    # Split the content into multiple chunks\n",
    "    documents = chart_text_splitter.create_documents([text])\n",
    "    \n",
    "    # Load the chain with ChatGPT\n",
    "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "    chain = load_summarize_chain(\n",
    "        llm=llm,\n",
    "        chain_type=\"map_reduce\",\n",
    "        combine_prompt=combine_prompt,\n",
    "    )\n",
    "\n",
    "    summary = chain.run(documents)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "for news_dict in top_news:\n",
    "    try:\n",
    "        summary = get_summary(news_dict[\"content\"])\n",
    "        news_dict[\"summary\"] = summary\n",
    "    except Exception as e:\n",
    "        news_dict[\"summary\"] = None\n",
    "\n",
    "print(top_news[0][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for news_dict in top_news:\n",
    "    # Save each news summary to a markdown file with the title of the article\n",
    "    with open(f\"summaries/{news_dict['title']}.md\", \"w\") as f:\n",
    "        f.write(news_dict[\"summary\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating images with Stable Diffusion\n",
    "\n",
    "## The Stable Diffusion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success',\n",
       " 'generationTime': 1.4018619060516357,\n",
       " 'id': 23877262,\n",
       " 'output': ['https://cdn.stablediffusionapi.com/generations/a83ed746-77b8-4c46-aa0d-04fb1bfa6bca-0.png'],\n",
       " 'meta': {'H': 512,\n",
       "  'W': 1024,\n",
       "  'enable_attention_slicing': 'true',\n",
       "  'file_prefix': 'a83ed746-77b8-4c46-aa0d-04fb1bfa6bca',\n",
       "  'guidance_scale': 7,\n",
       "  'model': 'runwayml/stable-diffusion-v1-5',\n",
       "  'n_samples': 1,\n",
       "  'negative_prompt': '',\n",
       "  'outdir': 'out',\n",
       "  'prompt': 'A man on the mooon',\n",
       "  'revision': 'fp16',\n",
       "  'safetychecker': 'no',\n",
       "  'seed': 2870945865,\n",
       "  'steps': 20,\n",
       "  'vae': 'stabilityai/sd-vae-ft-mse'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "STABLEDIFFUSION_API_KEY = os.environ.get(\"STABLEDIFFUSION_API_KEY\")\n",
    "\n",
    "url = \"https://stablediffusionapi.com/api/v3/text2img\"\n",
    "\n",
    "data = {\n",
    "    \"key\": STABLEDIFFUSION_API_KEY,\n",
    "    \"width\": \"1024\",\n",
    "    \"height\": \"512\",\n",
    "    \"prompt\": \"A man on the mooon\",\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the image\n",
    "image_url = response.json()[\"output\"][0]\n",
    "output_path = \"man_on_the_moon.png\"\n",
    "\n",
    "img_data = requests.get(image_url).content\n",
    "\n",
    "with open(output_path, \"wb\") as f:\n",
    "    f.write(img_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating images for the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "def submit_post(url, data):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    return requests.post(url, json=data, headers=headers)\n",
    "\n",
    "def save_image(image_url, output_path):\n",
    "    img_data = requests.get(image_url).content\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(img_data)\n",
    "\n",
    "for news in top_news:\n",
    "    data[\"prompt\"] = news[\"summary\"]\n",
    "    file_name = \"./summaries/\" + news[\"title\"] + \".png\"\n",
    "\n",
    "    try:\n",
    "        response = submit_post(url, data)\n",
    "        save_image(response.json()[\"output\"][0], file_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a title and abstract\n",
    "\n",
    "## The abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_template = \"\"\"\n",
    "Use the following article summaries to generate a 2 or 3 sentences abstract for a blog.\n",
    "\n",
    "Those articles are the most impactful news of the past week May 22nd 2023 to May 30th 2023.\n",
    "\n",
    "{summaries}\n",
    "\"\"\"\n",
    "\n",
    "ABSTRACT_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"summaries\"],\n",
    "    template=abstract_template,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=ABSTRACT_PROMPT,\n",
    ")\n",
    "\n",
    "summaries = \"\\n\\n\".join([\n",
    "    news[\"title\"] + \"\\n\" + news[\"summary\"]\n",
    "    for news in top_news\n",
    "])\n",
    "\n",
    "abstract = chain.run(summaries)\n",
    "\n",
    "# Save abstract in summaries/abstract.md\n",
    "with open(\"summaries/abstract.md\", \"w\") as f:\n",
    "    f.write(abstract)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The title\n",
    "\n",
    "For the title, a simple chain with work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_template = \"\"\"\n",
    "Use the following article summaries to generate a title for a blog about tech crunch news.\n",
    "Those articles are the most impactful news of the past week from May 22nd 2023 to May 30th 2023.\n",
    "The title need to be appealing such that people are excited to read the blog.\n",
    "\n",
    "{summaries}\n",
    "\"\"\"\n",
    "\n",
    "TITLE_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"summaries\"],\n",
    "    template=title_template,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=TITLE_PROMPT,\n",
    ")\n",
    "\n",
    "title = chain.run(summaries)\n",
    "\n",
    "# Save title in summaries/title.md\n",
    "with open(\"summaries/title.md\", \"w\") as f:\n",
    "    f.write(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
